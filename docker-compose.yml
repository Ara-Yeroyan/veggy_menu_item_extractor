services:
  api:
    build:
      context: .
      dockerfile: docker/api.Dockerfile
    ports:
      - "8000:8000"
    environment:
      - MCP_SERVER_URL=http://mcp-server:8001
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-true}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY:-}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-menu-parsing}
      - CONFIDENCE_THRESHOLD=${CONFIDENCE_THRESHOLD:-0.7}
      - HITL_THRESHOLD=${HITL_THRESHOLD:-0.5}
    depends_on:
      - mcp-server
    networks:
      - menu-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  mcp-server:
    build:
      context: .
      dockerfile: docker/mcp.Dockerfile
    ports:
      - "8001:8001"
    environment:
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-true}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY:-}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-menu-parsing}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-all-MiniLM-L6-v2}
      - RAG_TOP_K=${RAG_TOP_K:-5}
      - CONFIDENCE_THRESHOLD=${CONFIDENCE_THRESHOLD:-0.7}
      - HITL_THRESHOLD=${HITL_THRESHOLD:-0.5}
      - LLM_BATCH_ENABLED=${LLM_BATCH_ENABLED:-true}
      - LLM_BATCH_SIZE=${LLM_BATCH_SIZE:-8}
    networks:
      - menu-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    volumes:
      - model-cache:/root/.cache

networks:
  menu-network:
    driver: bridge

volumes:
  model-cache:
